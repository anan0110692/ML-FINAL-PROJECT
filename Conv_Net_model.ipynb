{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from dataset_batch import minibatch_train,minibatch_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#tf.reset_default_graph()        #this code is for retraining \n",
    "\n",
    "# create placeholder\n",
    "X=tf.placeholder(tf.float32,[None,128,128,3])\n",
    "Y=tf.placeholder(tf.float32,[None,2])\n",
    "\n",
    "keep_prob1 = tf.placeholder(tf.float32)  #use for dropout\n",
    "keep_prob2= tf.placeholder(tf.float32)\n",
    "# JOSE: this is an example code that i found, i was able to tweak the adam optimizer and saw the differences in convergence\n",
    "# also tried epochs and changing the architecture and it appears to work well. the adam optimizer is best when we are in the \n",
    "# 10e-5 or 10e-6 range and around 300 epochs for a dataset of 512 images. \n",
    "# the dataset pulled is from the dataset.h5 pile but it is only fed in batches due to the \"dataset batches.py\" file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abo_Alon\\anaconda3\\envs\\Python3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000027D40C70A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000027D40C70A58>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000027D40C70A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000027D40C70A58>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D40D146D8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D40D146D8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D40D146D8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D40D146D8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From <ipython-input-2-d45bedb425b6>:50: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D40B153C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D40B153C8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D40B153C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D40B153C8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D42A64FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D42A64FD0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D42A64FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000027D42A64FD0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From <ipython-input-2-d45bedb425b6>:61: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'minibatch_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d45bedb425b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# get the training images and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminibatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         _ , temp_cost = sess.run((train,cost),feed_dict={X:train_imgs,Y:train_labels,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'minibatch_train' is not defined"
     ]
    }
   ],
   "source": [
    "# conv1\n",
    "with tf.variable_scope('conv1') as scope:\n",
    "    weights = tf.get_variable('weights',shape = [3,3,3,16],dtype = tf.float32,                  \n",
    "                              initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    \n",
    "    biases = tf.get_variable('biases',shape = [16],dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.1))\n",
    "    \n",
    "    conv1 = tf.nn.relu(tf.nn.conv2d(X,weights,strides=[1,1,1,1],padding='SAME')+biases)\n",
    "        \n",
    "# pool1\n",
    "with tf.variable_scope('pool1') as scope:\n",
    "    pool1 = tf.nn.max_pool(conv1,ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "                           padding = 'SAME',name='pool1')\n",
    "\n",
    "# conv2\n",
    "with tf.variable_scope('conv2') as scope:\n",
    "    weights = tf.get_variable('weights',shape = [3,3,16,32],dtype = tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    \n",
    "    biases = tf.get_variable('biases',shape = [32],dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.1))\n",
    "    \n",
    "    conv2 = tf.nn.relu(tf.nn.conv2d(pool1,weights,strides=[1,1,1,1],padding='SAME')+biases)\n",
    "   \n",
    "# pool2\n",
    "with tf.variable_scope('pool2') as scope:\n",
    "     pool2 = tf.nn.max_pool(conv2,ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "                            padding = 'SAME',name='pool2')\n",
    "# conv3\n",
    "with tf.variable_scope('conv3') as scope:\n",
    "    weights = tf.get_variable('weights',shape = [3,3,32,32],dtype = tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    \n",
    "    biases = tf.get_variable('biases',shape = [32],dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.1))\n",
    "    \n",
    "    conv3 = tf.nn.relu(tf.nn.conv2d(pool2,weights,strides=[1,1,1,1],padding='SAME')+biases)\n",
    "   \n",
    "# pool3\n",
    "with tf.variable_scope('pool3') as scope:\n",
    "     pool3 = tf.nn.max_pool(conv3,ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "                            padding = 'SAME',name='pool3')\n",
    "    \n",
    "pool3_flatten=tf.contrib.layers.flatten(pool3)  #flatten pool3 to shape of (128,16*16*32)\n",
    "\n",
    "# fully connected layer 1 and dropout\n",
    "fc1=tf.contrib.layers.fully_connected(pool3_flatten,1024,activation_fn=tf.nn.relu)\n",
    "\n",
    "fc1_drop = tf.nn.dropout(fc1, keep_prob1)\n",
    "\n",
    "# fully connected layer 2 and dropout\n",
    "fc2=tf.contrib.layers.fully_connected(fc1_drop,64,activation_fn=tf.nn.relu)\n",
    "\n",
    "fc2_drop = tf.nn.dropout(fc2, keep_prob2)\n",
    "\n",
    "# fully connected layer 3                here activation_fn is None\n",
    "fc3=tf.contrib.layers.fully_connected(fc2_drop,2,activation_fn=None)\n",
    "\n",
    "# cost, train  \n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = fc3, labels = Y))\n",
    "\n",
    "train=tf.train.AdamOptimizer(0.00005).minimize(cost)\n",
    "\n",
    "# accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(fc3, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "train_batch_size=512   # minibatch for training\n",
    "test_batch_size=512    # minibatch for test\n",
    "seed=1                 # seed for shuffle training images,see cats_dogs_batch.py\n",
    "costs=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        seed=seed+1    # seed+1 every epoch to obtain different training batches\n",
    "       \n",
    "        # get the training images and labels \n",
    "        (train_imgs,train_labels)=minibatch_train(train_batch_size,seed)  \n",
    "        \n",
    "        _ , temp_cost = sess.run((train,cost),feed_dict={X:train_imgs,Y:train_labels,\n",
    "                                                         keep_prob1:0.5,keep_prob2:0.8})\n",
    "        if epoch % 10 == 0:\n",
    "            # keep_prob1 and keep_prob2 should be 1.0 when calculating accuracy\n",
    "            train_acc = accuracy.eval({X: train_imgs, Y: train_labels, \n",
    "                                       keep_prob1:1.0,keep_prob2:1.0})\n",
    "    \n",
    "            print(\"epoch: %d, cost: %f, training accuracy: %f\"%(epoch,temp_cost,train_acc))\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            # collect temp_cost for ploting the cost convergence figure\n",
    "            costs.append(temp_cost)   \n",
    "                \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()\n",
    "\n",
    "    #test accuracy\n",
    "    (test_imgs,test_labels)=minibatch_test(test_batch_size,seed)  \n",
    "    test_acc = accuracy.eval({X:test_imgs, Y:test_labels, keep_prob1:1.0, keep_prob2:1.0})\n",
    "    print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_batch_imgs,train_batch_labels) = minibatch_train(train_batch_size,seed) \n",
    "(test_imgs,test_labels)=minibatch_test(test_batch_size,seed)\n",
    "\n",
    "print(train_batch_imgs.shape)\n",
    "print(train_batch_labels.shape)\n",
    "print(train_batch_labels)\n",
    "# need to fix that the labels has 2 columns, this should only be one column. Go back to the Data Set sheet to fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 63\n",
    "plt.imshow(train_batch_imgs[index])\n",
    "print(train_batch_labels[index])\n",
    "# JOSE: idk why the train_batch_labels has two columns, can someone help with this please?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
