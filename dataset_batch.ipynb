{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# This module will be to create batches for our dataset that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_train(train_batch_size,seed):\n",
    "    \n",
    "    hdf5_path = 'Data/dataset.h5' # Change directory based on file you want to use\n",
    "    dataset = h5py.File(hdf5_path, \"r\")\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # shuffle indexes,int numbers range from 0 to 8012 (This number depends on the train/test set created in the \"Data Setup\" file)\n",
    "    permutation = list(np.random.permutation(8012))\n",
    "    \n",
    "    # get the \"train_batch_size\" indexes    \n",
    "    train_batch_index=permutation[0:train_batch_size]\n",
    "    \n",
    "    # the shape of \"train_labels\" now is (8012,1)\n",
    "    train_labels=np.array(dataset[\"train_labels\"]).reshape(8012,-1)\n",
    "    \n",
    "    # get the corresponding labels according \"train_batch_index\"\n",
    "    train_batch_labels=train_labels[train_batch_index]\n",
    "\n",
    "    train_batch_labels= np.eye(2)[train_batch_labels.reshape(-1)] #convert to one_hot code\n",
    "    \n",
    "    train_batch_imgs=[]\n",
    "    for i in range(train_batch_size):\n",
    "        img=(dataset['train_img'])[train_batch_index[i]]\n",
    "        img=img/255.\n",
    "        train_batch_imgs.append(img)    \n",
    "    train_batch_imgs=np.array(train_batch_imgs)\n",
    "    \n",
    "    dataset.close()\n",
    "    \n",
    "    return(train_batch_imgs,train_batch_labels)\n",
    "\n",
    "def minibatch_test(test_batch_size,seed): \n",
    "     \n",
    "    hdf5_path = 'Data/dataset.h5'\n",
    "    dataset = h5py.File(hdf5_path, \"r\")\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    permutation = list(np.random.permutation(2003))    \n",
    "    test_batch_index= permutation[0:test_batch_size]  \n",
    "    test_labels= np.array(dataset[\"test_labels\"]).reshape(2003,-1)\n",
    "    test_batch_labels= test_labels[test_batch_index]\n",
    "    test_batch_labels= np.eye(2)[test_batch_labels.reshape(-1)]\n",
    "    \n",
    "    test_batch_imgs=[]\n",
    "    for i in range(test_batch_size):\n",
    "        img=(dataset['test_img'])[test_batch_index[i]]\n",
    "        img=img/255.\n",
    "        test_batch_imgs.append(img)    \n",
    "    test_batch_imgs=np.array(test_batch_imgs)\n",
    "    \n",
    "    dataset.close()  \n",
    "    \n",
    "    return(test_batch_imgs,test_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytho",
   "language": "python",
   "name": "python_3.7.1_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
